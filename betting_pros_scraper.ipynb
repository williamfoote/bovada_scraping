{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.remote.remote_connection import RemoteConnection\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def american_odds_to_probability(american_odds):\n",
    "    if american_odds == '(EVEN)':\n",
    "        return 0.5\n",
    "    else:\n",
    "        odds = float(american_odds.replace('(', '').replace(')', ''))\n",
    "        if odds > 0:\n",
    "            return 100 / (odds + 100)\n",
    "        return abs(odds) / (abs(odds) + 100)\n",
    "    \n",
    "def get_player_and_odds_data(url):\n",
    "\n",
    "    # # Fetching the webpage content with custom headers\n",
    "    # headers = {\n",
    "    #     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    # }\n",
    "    # response = requests.get(url, headers=headers)\n",
    "\n",
    "    # # Check for HTTP status code issues\n",
    "    # if response.status_code == 403:\n",
    "    #     return \"403 Forbidden\", []\n",
    "    # elif response.status_code != 200:\n",
    "    #     return f\"Error {response.status_code}\", []\n",
    "\n",
    "    # # Parsing the content with BeautifulSoup\n",
    "    # soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "\n",
    "    # Fetching the webpage content\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    service = Service('/Users/williamfoote/Downloads/chromedriver-mac-arm64/chromedriver')\n",
    "    browser = webdriver.Chrome(service=service, options=options)\n",
    "    browser.get(url)\n",
    "    wait = WebDriverWait(browser, 10)  # Wait for up to 10 seconds\n",
    "    # Wait until the elements have loaded that we need\n",
    "    wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'odds-offer')))\n",
    "\n",
    "    # Create loop to scroll to the last element on the page, \n",
    "    # Break the loop if the no new elements are found\n",
    "    while True:\n",
    "        try:\n",
    "            # Find the last 'odds-offer' element\n",
    "            elements = browser.find_elements(By.CLASS_NAME, \"odds-offer\")\n",
    "            last_element = elements[-1] if elements else None\n",
    "\n",
    "            if not last_element:\n",
    "                break  # Break if no elements are found\n",
    "\n",
    "            # Scroll to the last element\n",
    "            browser.execute_script(\"arguments[0].scrollIntoView(true);\", last_element)\n",
    "\n",
    "            # Wait for new elements to load after scrolling\n",
    "            WebDriverWait(browser, 15).until(\n",
    "                lambda driver: len(driver.find_elements(By.CLASS_NAME, \"odds-offer\")) > len(elements)\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            # Break the loop if no new elements are found after the wait\n",
    "            break\n",
    "    # Create BeautifulSoup object after each scroll\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    browser.quit()\n",
    "    # Extracting player data and odds\n",
    "\n",
    "    player_data = []\n",
    "    # Odds offer is parent class\n",
    "    odds_offers = soup.find_all(\"div\", class_=\"odds-offer\")\n",
    "    date = datetime.strptime(url.split('date=')[-1], '%Y-%m-%d').date()\n",
    "    for offer in odds_offers:\n",
    "        # Finding player information\n",
    "        player_info = offer.find(\"div\", class_=\"odds-player__info odds-player__info--large\")\n",
    "        if player_info is None:\n",
    "            continue\n",
    "        player_link = player_info.find(\"a\", class_=\"link odds-player__heading odds-player__heading--large\")['href']\n",
    "\n",
    "        # Extract player position and matchup\n",
    "        player_position = player_info.find(\"p\", class_=\"typography odds-player__subheading\").text\n",
    "        team, position = player_position.split(' - ')\n",
    "        if position not in ['SP', 'RP', 'RP,SP', 'SP,RP', 'DH,SP']:\n",
    "            continue\n",
    "        player_matchup = player_info.find(\"div\", class_=\"odds-player__matchup-tag\").text\n",
    "        # Extracting the player's full name from the link\n",
    "        player_name = player_link.split('/')[-2].replace('-', ' ').title()\n",
    "        odds_container = offer.find(class_='odds-offer__item odds-offer__item--best-odds')\n",
    "        lines = odds_container.find_all(class_='typography odds-cell__line')\n",
    "        costs = odds_container.find_all(class_='typography odds-cell__cost')\n",
    "\n",
    "        over_line, under_line, over_cost_USA, under_cost_USA = None, None, None, None\n",
    "\n",
    "        for line, cost in zip(lines, costs):\n",
    "            if \"O \" in line.text:\n",
    "                over_line = float(line.text.replace(\"O \", \"\"))\n",
    "                over_cost_USA = cost.text\n",
    "            elif \"U \" in line.text:\n",
    "                under_line = float(line.text.replace(\"U \", \"\"))\n",
    "                under_cost_USA = cost.text\n",
    "\n",
    "        # Convert American odds to probability if they are available\n",
    "        over_cost = american_odds_to_probability(over_cost_USA) if over_cost_USA else None\n",
    "        under_cost = american_odds_to_probability(under_cost_USA) if under_cost_USA else None\n",
    "\n",
    "        # Check if over_line and under_line are not None before proceeding\n",
    "        if over_line is not None and under_line is not None:\n",
    "        # Adding the extracted data to the player data list\n",
    "            player_data.append({\n",
    "                \"name\": player_name,\n",
    "                \"team\": team,\n",
    "                \"position\": position,\n",
    "                \"matchup\": player_matchup,\n",
    "                \"over_line\": over_line,\n",
    "                \"under_line\": under_line,\n",
    "                \"over_cost\": over_cost,\n",
    "                \"under_cost\": under_cost,\n",
    "                \"over_cost_USA\": over_cost_USA,\n",
    "                \"under_cost_USA\": under_cost_USA,\n",
    "                \"date\": date\n",
    "            })\n",
    "    return player_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully scraped data for 2023-03-30\n",
      "Successfully scraped data for 2023-03-31\n",
      "Successfully scraped data for 2023-04-01\n",
      "Successfully scraped data for 2023-04-02\n",
      "Successfully scraped data for 2023-04-03\n",
      "Successfully scraped data for 2023-04-04\n",
      "Successfully scraped data for 2023-04-05\n",
      "Successfully scraped data for 2023-04-06\n",
      "Successfully scraped data for 2023-04-07\n",
      "Successfully scraped data for 2023-04-08\n",
      "Successfully scraped data for 2023-04-09\n",
      "Successfully scraped data for 2023-04-10\n",
      "Successfully scraped data for 2023-04-11\n",
      "Successfully scraped data for 2023-04-12\n",
      "Successfully scraped data for 2023-04-13\n",
      "Successfully scraped data for 2023-04-14\n",
      "Successfully scraped data for 2023-04-15\n",
      "Successfully scraped data for 2023-04-16\n",
      "Successfully scraped data for 2023-04-17\n",
      "Successfully scraped data for 2023-04-18\n",
      "Successfully scraped data for 2023-04-19\n",
      "Successfully scraped data for 2023-04-20\n",
      "Successfully scraped data for 2023-04-21\n",
      "Successfully scraped data for 2023-04-22\n",
      "Successfully scraped data for 2023-04-23\n",
      "Successfully scraped data for 2023-04-24\n",
      "Successfully scraped data for 2023-04-25\n",
      "Successfully scraped data for 2023-04-26\n",
      "Successfully scraped data for 2023-04-27\n",
      "Successfully scraped data for 2023-04-28\n",
      "Successfully scraped data for 2023-04-29\n",
      "Successfully scraped data for 2023-04-30\n",
      "Successfully scraped data for 2023-05-01\n",
      "Successfully scraped data for 2023-05-02\n",
      "Successfully scraped data for 2023-05-03\n",
      "Successfully scraped data for 2023-05-04\n",
      "Successfully scraped data for 2023-05-05\n",
      "Successfully scraped data for 2023-05-06\n",
      "Successfully scraped data for 2023-05-07\n",
      "Successfully scraped data for 2023-05-08\n",
      "Successfully scraped data for 2023-05-09\n",
      "Successfully scraped data for 2023-05-10\n",
      "Successfully scraped data for 2023-05-11\n",
      "Successfully scraped data for 2023-05-12\n",
      "Successfully scraped data for 2023-05-13\n",
      "Successfully scraped data for 2023-05-14\n",
      "Successfully scraped data for 2023-05-15\n",
      "Successfully scraped data for 2023-05-16\n",
      "Successfully scraped data for 2023-05-17\n",
      "Successfully scraped data for 2023-05-18\n",
      "Successfully scraped data for 2023-05-19\n",
      "Successfully scraped data for 2023-05-20\n",
      "Successfully scraped data for 2023-05-21\n",
      "Successfully scraped data for 2023-05-22\n",
      "Successfully scraped data for 2023-05-23\n",
      "Successfully scraped data for 2023-05-24\n",
      "Successfully scraped data for 2023-05-25\n",
      "Successfully scraped data for 2023-05-26\n",
      "Successfully scraped data for 2023-05-27\n",
      "Successfully scraped data for 2023-05-28\n",
      "Successfully scraped data for 2023-05-29\n",
      "Successfully scraped data for 2023-05-30\n",
      "Successfully scraped data for 2023-05-31\n",
      "Successfully scraped data for 2023-06-01\n",
      "Successfully scraped data for 2023-06-02\n",
      "Successfully scraped data for 2023-06-03\n",
      "Successfully scraped data for 2023-06-04\n",
      "Successfully scraped data for 2023-06-05\n",
      "Successfully scraped data for 2023-06-06\n",
      "Successfully scraped data for 2023-06-07\n",
      "Successfully scraped data for 2023-06-08\n",
      "Successfully scraped data for 2023-06-09\n",
      "Successfully scraped data for 2023-06-10\n",
      "Successfully scraped data for 2023-06-11\n",
      "Successfully scraped data for 2023-06-12\n",
      "Successfully scraped data for 2023-06-13\n",
      "Successfully scraped data for 2023-06-14\n",
      "Successfully scraped data for 2023-06-15\n",
      "Successfully scraped data for 2023-06-16\n",
      "Successfully scraped data for 2023-06-17\n",
      "Successfully scraped data for 2023-06-18\n",
      "Successfully scraped data for 2023-06-19\n",
      "Successfully scraped data for 2023-06-20\n",
      "Successfully scraped data for 2023-06-21\n",
      "Successfully scraped data for 2023-06-22\n",
      "Successfully scraped data for 2023-06-23\n",
      "Successfully scraped data for 2023-06-24\n",
      "Successfully scraped data for 2023-06-25\n",
      "Successfully scraped data for 2023-06-26\n",
      "Successfully scraped data for 2023-06-27\n",
      "Successfully scraped data for 2023-06-28\n",
      "Successfully scraped data for 2023-06-29\n",
      "Successfully scraped data for 2023-06-30\n",
      "Successfully scraped data for 2023-07-01\n",
      "Successfully scraped data for 2023-07-02\n",
      "Successfully scraped data for 2023-07-03\n",
      "Successfully scraped data for 2023-07-04\n",
      "Successfully scraped data for 2023-07-05\n",
      "No data on 2023-07-06\n",
      "Successfully scraped data for 2023-07-07\n",
      "Successfully scraped data for 2023-07-08\n",
      "Successfully scraped data for 2023-07-09\n",
      "No data on 2023-07-10\n",
      "No data on 2023-07-11\n",
      "No data on 2023-07-12\n",
      "No data on 2023-07-13\n",
      "Successfully scraped data for 2023-07-14\n",
      "Successfully scraped data for 2023-07-15\n",
      "Successfully scraped data for 2023-07-16\n",
      "Successfully scraped data for 2023-07-17\n",
      "Successfully scraped data for 2023-07-18\n",
      "Successfully scraped data for 2023-07-19\n",
      "Successfully scraped data for 2023-07-20\n",
      "Successfully scraped data for 2023-07-21\n",
      "Successfully scraped data for 2023-07-22\n",
      "Successfully scraped data for 2023-07-23\n",
      "Successfully scraped data for 2023-07-24\n",
      "Successfully scraped data for 2023-07-25\n",
      "Successfully scraped data for 2023-07-26\n",
      "Successfully scraped data for 2023-07-27\n",
      "Successfully scraped data for 2023-07-28\n",
      "Successfully scraped data for 2023-07-29\n",
      "Successfully scraped data for 2023-07-30\n",
      "Successfully scraped data for 2023-07-31\n",
      "Successfully scraped data for 2023-08-01\n",
      "Successfully scraped data for 2023-08-02\n",
      "Successfully scraped data for 2023-08-03\n",
      "Successfully scraped data for 2023-08-04\n",
      "Successfully scraped data for 2023-08-05\n",
      "Successfully scraped data for 2023-08-06\n",
      "Successfully scraped data for 2023-08-07\n",
      "Successfully scraped data for 2023-08-08\n",
      "Successfully scraped data for 2023-08-09\n",
      "Successfully scraped data for 2023-08-10\n",
      "Successfully scraped data for 2023-08-11\n",
      "Successfully scraped data for 2023-08-12\n",
      "Successfully scraped data for 2023-08-13\n",
      "Successfully scraped data for 2023-08-14\n",
      "Successfully scraped data for 2023-08-15\n",
      "Successfully scraped data for 2023-08-16\n",
      "Successfully scraped data for 2023-08-17\n",
      "Successfully scraped data for 2023-08-18\n",
      "Successfully scraped data for 2023-08-19\n",
      "Successfully scraped data for 2023-08-20\n",
      "Successfully scraped data for 2023-08-21\n",
      "Successfully scraped data for 2023-08-22\n",
      "Successfully scraped data for 2023-08-23\n",
      "Successfully scraped data for 2023-08-24\n",
      "Successfully scraped data for 2023-08-25\n",
      "Successfully scraped data for 2023-08-26\n",
      "Successfully scraped data for 2023-08-27\n",
      "Successfully scraped data for 2023-08-28\n",
      "Successfully scraped data for 2023-08-29\n",
      "Successfully scraped data for 2023-08-30\n",
      "Successfully scraped data for 2023-08-31\n",
      "Successfully scraped data for 2023-09-01\n",
      "Successfully scraped data for 2023-09-02\n",
      "Successfully scraped data for 2023-09-03\n",
      "Successfully scraped data for 2023-09-04\n",
      "Successfully scraped data for 2023-09-05\n",
      "Successfully scraped data for 2023-09-06\n",
      "Successfully scraped data for 2023-09-07\n",
      "Successfully scraped data for 2023-09-08\n",
      "Successfully scraped data for 2023-09-09\n",
      "Successfully scraped data for 2023-09-10\n",
      "Successfully scraped data for 2023-09-11\n",
      "Successfully scraped data for 2023-09-12\n",
      "Successfully scraped data for 2023-09-13\n",
      "Successfully scraped data for 2023-09-14\n",
      "Successfully scraped data for 2023-09-15\n",
      "Successfully scraped data for 2023-09-16\n",
      "Successfully scraped data for 2023-09-17\n",
      "Successfully scraped data for 2023-09-18\n",
      "Successfully scraped data for 2023-09-19\n",
      "Successfully scraped data for 2023-09-20\n",
      "Successfully scraped data for 2023-09-21\n",
      "Successfully scraped data for 2023-09-22\n",
      "Successfully scraped data for 2023-09-23\n",
      "Successfully scraped data for 2023-09-24\n",
      "Successfully scraped data for 2023-09-25\n",
      "Successfully scraped data for 2023-09-26\n",
      "Successfully scraped data for 2023-09-27\n",
      "Successfully scraped data for 2023-09-28\n",
      "Successfully scraped data for 2023-09-29\n",
      "Successfully scraped data for 2023-09-30\n",
      "Successfully scraped data for 2023-10-01\n",
      "Successfully scraped data for 2023-10-02\n",
      "Successfully scraped data for 2023-10-03\n",
      "Successfully scraped data for 2023-10-04\n",
      "No data on 2023-10-05\n",
      "No data on 2023-10-06\n",
      "Successfully scraped data for 2023-10-07\n",
      "Successfully scraped data for 2023-10-08\n",
      "Successfully scraped data for 2023-10-09\n",
      "Successfully scraped data for 2023-10-10\n",
      "Successfully scraped data for 2023-10-11\n",
      "Successfully scraped data for 2023-10-12\n",
      "No data on 2023-10-13\n",
      "No data on 2023-10-14\n",
      "Successfully scraped data for 2023-10-15\n",
      "Successfully scraped data for 2023-10-16\n",
      "Successfully scraped data for 2023-10-17\n",
      "Successfully scraped data for 2023-10-18\n",
      "Successfully scraped data for 2023-10-19\n",
      "Successfully scraped data for 2023-10-20\n",
      "Successfully scraped data for 2023-10-21\n",
      "Successfully scraped data for 2023-10-22\n",
      "Successfully scraped data for 2023-10-23\n",
      "Successfully scraped data for 2023-10-24\n",
      "No data on 2023-10-25\n",
      "No data on 2023-10-26\n",
      "Successfully scraped data for 2023-10-27\n",
      "Successfully scraped data for 2023-10-28\n",
      "No data on 2023-10-29\n",
      "Successfully scraped data for 2023-10-30\n",
      "Successfully scraped data for 2023-10-31\n",
      "Successfully scraped data for 2023-11-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = datetime(2023, 3, 30)  # Start of the season\n",
    "end_date = datetime(2023, 11, 1)   # End of the season\n",
    "delta = timedelta(days=1)\n",
    "\n",
    "all_data = []\n",
    "\n",
    "while start_date <= end_date:\n",
    "    date_str = start_date.strftime('%Y-%m-%d')\n",
    "    url = f\"https://www.bettingpros.com/mlb/odds/player-props/strikeouts/?date={date_str}\"\n",
    "    try:\n",
    "        daily_data = get_player_and_odds_data(url)\n",
    "        if daily_data:  # Check if data is not empty\n",
    "            all_data.extend(daily_data)\n",
    "            print(f\"Successfully scraped data for {date_str}\")\n",
    "    except Exception as e:\n",
    "        print(f\"No data on {date_str}\")\n",
    "    finally:\n",
    "        start_date += delta\n",
    "        sleep_time = random.uniform(5, 10)  # Random sleep time between 5 and 10 seconds\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "season_df = pd.DataFrame(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SP', 'SP,RP', 'RP,SP', 'RP', 'DH,SP'], dtype=object)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may = season_df\n",
    "may['position'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "export2.to_csv('/Users/williamfoote/Documents/GitHub/bovada_scraping/data/2023/all_2023.csv')\n",
    "# may_21.to_csv('/Users/williamfoote/Documents/GitHub/bovada_scraping/data/2021/may.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a test URL or insert the URL that is messing up\n",
    "Identify the error and adjust code above to fix the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "export2 = pd.concat([season_df, df], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>team</th>\n",
       "      <th>position</th>\n",
       "      <th>matchup</th>\n",
       "      <th>over_line</th>\n",
       "      <th>under_line</th>\n",
       "      <th>over_cost</th>\n",
       "      <th>under_cost</th>\n",
       "      <th>over_cost_USA</th>\n",
       "      <th>under_cost_USA</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shane Bieber</td>\n",
       "      <td>CLE</td>\n",
       "      <td>SP</td>\n",
       "      <td>CLE at DET</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>(-140)</td>\n",
       "      <td>(+120)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael Pineda</td>\n",
       "      <td>FA</td>\n",
       "      <td>SP</td>\n",
       "      <td>CLE at DET</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.460829</td>\n",
       "      <td>(-130)</td>\n",
       "      <td>(+117)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corbin Burnes</td>\n",
       "      <td>BAL</td>\n",
       "      <td>SP</td>\n",
       "      <td>CHC at MIL</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.547511</td>\n",
       "      <td>(EVEN)</td>\n",
       "      <td>(-121)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adrian Sampson</td>\n",
       "      <td>FA</td>\n",
       "      <td>SP</td>\n",
       "      <td>CHC at MIL</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.625468</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>(-167)</td>\n",
       "      <td>(-156)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lance Lynn</td>\n",
       "      <td>STL</td>\n",
       "      <td>SP</td>\n",
       "      <td>MIN at CWS</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>(-115)</td>\n",
       "      <td>(-110)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Joe Ryan</td>\n",
       "      <td>MIN</td>\n",
       "      <td>SP</td>\n",
       "      <td>MIN at CWS</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>(-152)</td>\n",
       "      <td>(-155)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jose Berrios</td>\n",
       "      <td>TOR</td>\n",
       "      <td>SP</td>\n",
       "      <td>TOR at OAK</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(-136)</td>\n",
       "      <td>(+110)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>James Kaprielian</td>\n",
       "      <td>FA</td>\n",
       "      <td>SP</td>\n",
       "      <td>TOR at OAK</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>(-152)</td>\n",
       "      <td>(+128)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shohei Ohtani</td>\n",
       "      <td>LAD</td>\n",
       "      <td>DH,SP</td>\n",
       "      <td>LAA at MIA</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>(+120)</td>\n",
       "      <td>(-152)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trevor Rogers</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SP</td>\n",
       "      <td>LAA at MIA</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.618321</td>\n",
       "      <td>0.557522</td>\n",
       "      <td>(-162)</td>\n",
       "      <td>(-126)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>David Peterson</td>\n",
       "      <td>NYM</td>\n",
       "      <td>SP,RP</td>\n",
       "      <td>NYM at CIN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.588477</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>(-143)</td>\n",
       "      <td>(-136)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Graham Ashcraft</td>\n",
       "      <td>CIN</td>\n",
       "      <td>SP</td>\n",
       "      <td>NYM at CIN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>(+110)</td>\n",
       "      <td>(-120)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mitch Keller</td>\n",
       "      <td>PIT</td>\n",
       "      <td>SP</td>\n",
       "      <td>NYY at PIT</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.585062</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>(-141)</td>\n",
       "      <td>(+135)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Luis Severino</td>\n",
       "      <td>NYM</td>\n",
       "      <td>SP</td>\n",
       "      <td>NYY at PIT</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>(-145)</td>\n",
       "      <td>(-118)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aaron Nola</td>\n",
       "      <td>PHI</td>\n",
       "      <td>SP</td>\n",
       "      <td>WSH at PHI</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.557522</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>(-126)</td>\n",
       "      <td>(+105)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Josiah Gray</td>\n",
       "      <td>WSH</td>\n",
       "      <td>SP</td>\n",
       "      <td>WSH at PHI</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.588477</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>(-143)</td>\n",
       "      <td>(-130)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Brayan Bello</td>\n",
       "      <td>BOS</td>\n",
       "      <td>SP</td>\n",
       "      <td>TB at BOS</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>(-115)</td>\n",
       "      <td>(+104)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Corey Kluber</td>\n",
       "      <td>FA</td>\n",
       "      <td>RP,SP</td>\n",
       "      <td>TB at BOS</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>(+115)</td>\n",
       "      <td>(-140)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Max Fried</td>\n",
       "      <td>ATL</td>\n",
       "      <td>SP</td>\n",
       "      <td>STL at ATL</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>(+125)</td>\n",
       "      <td>(-136)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Miles Mikolas</td>\n",
       "      <td>STL</td>\n",
       "      <td>SP</td>\n",
       "      <td>STL at ATL</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>(-105)</td>\n",
       "      <td>(-109)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cristian Javier</td>\n",
       "      <td>HOU</td>\n",
       "      <td>SP</td>\n",
       "      <td>KC at HOU</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>(-120)</td>\n",
       "      <td>(+104)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Brad Keller</td>\n",
       "      <td>FA</td>\n",
       "      <td>SP,RP</td>\n",
       "      <td>KC at HOU</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.624060</td>\n",
       "      <td>(-155)</td>\n",
       "      <td>(-166)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Merrill Kelly</td>\n",
       "      <td>ARI</td>\n",
       "      <td>SP</td>\n",
       "      <td>SF at ARI</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.572650</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>(-134)</td>\n",
       "      <td>(+110)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Alex Cobb</td>\n",
       "      <td>SF</td>\n",
       "      <td>SP</td>\n",
       "      <td>SF at ARI</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>(-106)</td>\n",
       "      <td>(-110)</td>\n",
       "      <td>2022-07-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name team position     matchup  over_line  under_line  \\\n",
       "0       Shane Bieber  CLE       SP  CLE at DET        6.5         6.5   \n",
       "1     Michael Pineda   FA       SP  CLE at DET        2.5         2.5   \n",
       "2      Corbin Burnes  BAL       SP  CHC at MIL        8.5         8.5   \n",
       "3     Adrian Sampson   FA       SP  CHC at MIL        3.5         4.5   \n",
       "4         Lance Lynn  STL       SP  MIN at CWS        5.5         5.5   \n",
       "5           Joe Ryan  MIN       SP  MIN at CWS        4.5         5.5   \n",
       "6       Jose Berrios  TOR       SP  TOR at OAK        4.5         4.5   \n",
       "7   James Kaprielian   FA       SP  TOR at OAK        3.5         3.5   \n",
       "8      Shohei Ohtani  LAD    DH,SP  LAA at MIA        7.5         7.5   \n",
       "9      Trevor Rogers  MIA       SP  LAA at MIA        4.5         5.5   \n",
       "10    David Peterson  NYM    SP,RP  NYM at CIN        4.5         5.5   \n",
       "11   Graham Ashcraft  CIN       SP  NYM at CIN        3.5         3.5   \n",
       "12      Mitch Keller  PIT       SP  NYY at PIT        3.5         3.5   \n",
       "13     Luis Severino  NYM       SP  NYY at PIT        5.5         6.5   \n",
       "14        Aaron Nola  PHI       SP  WSH at PHI        6.5         6.5   \n",
       "15       Josiah Gray  WSH       SP  WSH at PHI        4.5         5.5   \n",
       "16      Brayan Bello  BOS       SP   TB at BOS        4.5         4.5   \n",
       "17      Corey Kluber   FA    RP,SP   TB at BOS        4.5         4.5   \n",
       "18         Max Fried  ATL       SP  STL at ATL        5.5         5.5   \n",
       "19     Miles Mikolas  STL       SP  STL at ATL        4.5         4.5   \n",
       "20   Cristian Javier  HOU       SP   KC at HOU        6.5         6.5   \n",
       "21       Brad Keller   FA    SP,RP   KC at HOU        3.5         4.5   \n",
       "22     Merrill Kelly  ARI       SP   SF at ARI        4.5         4.5   \n",
       "23         Alex Cobb   SF       SP   SF at ARI        4.5         4.5   \n",
       "\n",
       "    over_cost  under_cost over_cost_USA under_cost_USA        date  \n",
       "0    0.583333    0.454545        (-140)         (+120)  2022-07-06  \n",
       "1    0.565217    0.460829        (-130)         (+117)  2022-07-06  \n",
       "2    0.500000    0.547511        (EVEN)         (-121)  2022-07-06  \n",
       "3    0.625468    0.609375        (-167)         (-156)  2022-07-06  \n",
       "4    0.534884    0.523810        (-115)         (-110)  2022-07-06  \n",
       "5    0.603175    0.607843        (-152)         (-155)  2022-07-06  \n",
       "6    0.576271    0.476190        (-136)         (+110)  2022-07-06  \n",
       "7    0.603175    0.438596        (-152)         (+128)  2022-07-06  \n",
       "8    0.454545    0.603175        (+120)         (-152)  2022-07-06  \n",
       "9    0.618321    0.557522        (-162)         (-126)  2022-07-06  \n",
       "10   0.588477    0.576271        (-143)         (-136)  2022-07-06  \n",
       "11   0.476190    0.545455        (+110)         (-120)  2022-07-06  \n",
       "12   0.585062    0.425532        (-141)         (+135)  2022-07-06  \n",
       "13   0.591837    0.541284        (-145)         (-118)  2022-07-06  \n",
       "14   0.557522    0.487805        (-126)         (+105)  2022-07-06  \n",
       "15   0.588477    0.565217        (-143)         (-130)  2022-07-06  \n",
       "16   0.534884    0.490196        (-115)         (+104)  2022-07-06  \n",
       "17   0.465116    0.583333        (+115)         (-140)  2022-07-06  \n",
       "18   0.444444    0.576271        (+125)         (-136)  2022-07-06  \n",
       "19   0.512195    0.521531        (-105)         (-109)  2022-07-06  \n",
       "20   0.545455    0.490196        (-120)         (+104)  2022-07-06  \n",
       "21   0.607843    0.624060        (-155)         (-166)  2022-07-06  \n",
       "22   0.572650    0.476190        (-134)         (+110)  2022-07-06  \n",
       "23   0.514563    0.523810        (-106)         (-110)  2022-07-06  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_url = 'https://www.bettingpros.com/mlb/odds/player-props/strikeouts/?date=2022-07-06'\n",
    "data = get_player_and_odds_data(test_url)\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If needed, edit the code below to get the css items that are missing or incorrectly accessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the webpage content\n",
    "options = Options()\n",
    "options.headless = True\n",
    "service = Service('/Users/williamfoote/Downloads/chromedriver-mac-arm64/chromedriver')\n",
    "browser = webdriver.Chrome(service=service, options=options)\n",
    "browser.get(test_url)\n",
    "wait = WebDriverWait(browser, 10)  # Wait for up to 10 seconds\n",
    "\n",
    "\n",
    "# Wait until the elements have loaded that we need\n",
    "wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'odds-offer')))\n",
    "html = browser.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "browser.quit()\n",
    "# Extracting player data and odds\n",
    "\n",
    "\n",
    "\n",
    "player_data = []\n",
    "# Odds offer is parent class\n",
    "odds_offers = soup.find_all(\"div\", class_=\"grouped-items-with-sticky-footer__content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds_offers = soup.find_all(\"div\", class_=\"grouped-items-with-sticky-footer__content\")\n",
    "len(odds_offers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all(By.CLASS_NAME, \"grouped-items-with-sticky-footer__content\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_container = odds_offers[3].find(class_='odds-offer__item odds-offer__item--best-odds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+1.0(+1100)'"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds_container.find_all(class_='odds-cell odds-cell--best odds-cell--event-completed')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PHI - SP'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_info = offer.find(\"div\", class_=\"odds-player__info odds-player__info--large\")\n",
    "player_position = player_info.find(\"p\", class_=\"typography odds-player__subheading\").text\n",
    "\n",
    "# if player_info is None:\n",
    "#     continue\n",
    "# player_link = player_info.find(\"a\", class_=\"link odds-player__heading odds-player__heading--large\")['href']\n",
    "\n",
    "# # Extracting the player's full name from the link\n",
    "# player_name = player_link.split('/')[-2].replace('-', ' ').title()\n",
    "\n",
    "# # Extract player position and matchup\n",
    "# player_position = player_info.find(\"p\", class_=\"typography odds-player__subheading\").text\n",
    "# if player_position not in ['SP', 'RP', 'RP,SP', 'SP,RP', 'DH,SP']:\n",
    "#     continue\n",
    "# player_matchup = player_info.find(\"div\", class_=\"odds-player__matchup-tag\").text\n",
    "player_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"odds-player__info odds-player__info--large\" data-v-e8516d98=\"\"><div class=\"odds-player__matchup-tag\" data-v-e8516d98=\"\">MIA at NYM</div><a class=\"link odds-player__heading odds-player__heading--large\" data-v-e8516d98=\"\" href=\"/mlb/odds/player-props/taijuan-walker/\" style=\"--ef09f0fa: #16191D; --fe392e3c: block; --bf535660: 1.8rem; --2ab080f2: 700;\" target=\"_self\">T. Walker</a><p class=\"typography odds-player__subheading\" data-v-e8516d98=\"\" data-v-f8c6c06d=\"\" style=\"--64dcb17e: #525A67; --0b8a2e86: 1.2rem; --584c03bd: 600; --6553e651: 170%; --faa089fc: left; --97ef6e2e: none; --da5e331a: nowrap;\">PHI - SP</p></div>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[227], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Finding player information\u001b[39;00m\n\u001b[1;32m      2\u001b[0m player_info \u001b[38;5;241m=\u001b[39m odds_offers[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124modds-player__info odds-player__info--large\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m player_link \u001b[38;5;241m=\u001b[39m \u001b[43mplayer_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink odds-player__heading odds-player__heading--large\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Extracting the player's full name from the link\u001b[39;00m\n\u001b[1;32m      6\u001b[0m player_name \u001b[38;5;241m=\u001b[39m player_link\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtitle()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "# Finding player information\n",
    "player_info = odds_offers[4].find(\"div\", class_=\"odds-player__info odds-player__info--large\")\n",
    "player_link = player_info.find(\"a\", class_=\"link odds-player__heading odds-player__heading--large\")['href']\n",
    "\n",
    "# Extracting the player's full name from the link\n",
    "player_name = player_link.split('/')[-2].replace('-', ' ').title()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
